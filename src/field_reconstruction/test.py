import torch
import os
import numpy as np
from tqdm import tqdm
from models import FukamiNet, ReconstructionVAE
from models.diffusion.diffusion_unet import SimpleUnet
from models.diffusion.ddpm import DDPM
import matplotlib.pyplot as plt
from utils import get_device
from plots_creator import plot_random_reconstruction, plot_l2_error_distributions
from utils import create_model, get_device
from scipy.interpolate import griddata
from skimage.metrics import structural_similarity as ssim
from pykrige.ok import OrdinaryKriging

from pathlib import Path  # <-- make sure this is imported

def kriging_interpolation(yx, values, H, W, model='exponential'):
    x = yx[:, 1].astype(np.float64)
    y = yx[:, 0].astype(np.float64)
    z = values.astype(np.float64)

    gridx = np.arange(W, dtype=float)
    gridy = np.arange(H, dtype=float)

    try:
        ok = OrdinaryKriging(x, y, z, variogram_model=model, verbose=False, enable_plotting=False)
        interp, _ = ok.execute('grid', gridx, gridy)
    except Exception as e:
        print(f"Kriging failed: {e}")
        interp = np.zeros((H, W))  # fallback

    return interp

def rrmse(pred, target):
    """
    The function calculates the relative root mean square error between two input tensors.
    
    :param pred: The `pred` parameter typically refers to the predicted values from a model, while the
    `target` parameter refers to the actual target values. The function `rrmse` seems to be calculating
    the Root Relative Mean Squared Error (RRMSE) between the predicted values and the target values
    :param target: The `target` parameter typically refers to the ground truth values or the actual
    values that you are trying to predict or model. In the context of the `rrmse` function you provided,
    `target` is likely the true target values that you are comparing against the predicted values
    (`pred`)
    :return: the Relative Root Mean Squared Error (RRMSE) between the predicted values (pred) and the
    target values.
    """
    
    return torch.sqrt(torch.mean((pred - target) ** 2)) / torch.sqrt(torch.mean(target ** 2))

def mae(pred, target):
    """
    The function calculates the mean absolute error between two input tensors.
    
    :param pred: The `pred` parameter typically refers to the predicted values generated by a model,
    while the `target` parameter refers to the actual target values that the model is trying to predict.
    The `mae` function calculates the Mean Absolute Error (MAE) between the predicted values (`pred`)
    and the
    :param target: The `target` parameter typically refers to the true or actual values that you are
    trying to predict or estimate in a machine learning model. It is the ground truth against which your
    predictions are compared
    :return: The function `mae` returns the mean absolute error between the `pred` and `target` tensors
    using the torch library.
    """
    return torch.mean(torch.abs(pred - target))

def evaluate_interp(test_loader, mode: str = 'cubic', nb_channels: int = 2, variable_names=None):
    device = get_device()

    print(f"âœ… Evaluating model on {len(test_loader.dataset)} samples")
    print(f"âœ… Model type: Interpolation ({mode})")
    print(f"âœ… Device: {device}")
    
    rrmse_total = []
    mae_total = []
    ssim_total = []
    l2_errors = [[] for _ in range(nb_channels)]
    n = 0
    num_vars = None

    with torch.no_grad():
        pbar = tqdm(test_loader, desc="Testing")

        for inputs, targets in pbar:
            inputs, targets = inputs.to(device), targets.to(device)
            inputs_np = inputs.cpu().numpy()   # (B, 1 + Nvars, H, W)
            targets_np = targets.cpu().numpy() # (B, Nvars, H, W)

            B, C, H, W = inputs_np.shape
            num_vars = C - 1  # First channel is the shared mask

            preds = []

            for i in range(B):
                mask = inputs_np[i, 0, :, :]  # shape: (H, W)
                yx = np.argwhere(mask > 0)

                pred_sample = []
                for v in range(num_vars):
                    voronoi = inputs_np[i, v + 1, :, :]  # v-th variable's tessellated field
                    values = voronoi[mask > 0]

                    grid_y, grid_x = np.meshgrid(np.arange(H), np.arange(W), indexing="ij")
                    if mode in ['linear', 'cubic']:
                        interp = griddata(yx, values, (grid_y, grid_x), method=mode, fill_value=0.0)
                    elif mode == "kriging":
                        interp = kriging_interpolation(yx, values, H, W)
                    pred_sample.append(torch.tensor(interp, dtype=torch.float32))

                preds.append(torch.stack(pred_sample))  # (Nvars, H, W)

            preds = torch.stack(preds).to(device)  # (B, Nvars, H, W)

            rrmse_batch = []
            mae_batch = []
            ssim_batch = []

            for v in range(num_vars):
                pred_v = preds[:, v, :, :]
                target_v = targets[:, v, :, :]

                rrmse_v = rrmse(pred_v, target_v).item()
                mae_v = mae(pred_v, target_v).item()
                ssim_v = np.mean([
                    ssim(
                        pred_v[i].cpu().numpy().astype(np.float32),
                        target_v[i].cpu().numpy().astype(np.float32),
                        data_range=(target_v[i].max() - target_v[i].min() + 1e-8).item()
                    )
                    for i in range(pred_v.shape[0])
                ])

                l2_v = ((pred_v - target_v) ** 2).mean(dim=(1, 2))
                l2_errors[v].extend(l2_v.tolist())
                
                rrmse_batch.append(rrmse_v)
                mae_batch.append(mae_v)
                ssim_batch.append(ssim_v)
                

            rrmse_total.append(np.array(rrmse_batch) * B)
            mae_total.append(np.array(mae_batch) * B)
            ssim_total.append(np.array(ssim_batch) * B)
            n += B

            pbar.set_postfix({
                "RRMSE": np.mean(rrmse_batch),
                "MAE": np.mean(mae_batch),
            })

    rrmse_total = np.sum(rrmse_total, axis=0) / n
    mae_total = np.sum(mae_total, axis=0) / n
    ssim_total = np.sum(ssim_total, axis=0) / n

    if variable_names is None:
        variable_names = [f"Var{i}" for i in range(len(rrmse_total))]

    print("ðŸ“ˆ Per-variable Metrics:")
    for idx, var in enumerate(variable_names):
        print(f"âœ… {var}: RRMSE={rrmse_total[idx]:.4f}, MAE={mae_total[idx]:.4f}, SSIM={ssim_total[idx]:.4f}")

    print("\nðŸ“Š Overall Averages:")
    print(f"âœ… Avg RRMSE={np.mean(rrmse_total):.4f}, Avg MAE={np.mean(mae_total):.4f}, Avg SSIM={np.mean(ssim_total):.4f}")

    # Convert to dict
    l2_errors_dict = {var: l2_errors[i] for i, var in enumerate(variable_names)}

    # ðŸ“Š Plot L2 Error Distributions
    save_dir = Path("plots/evaluation")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    
    if mode == "kriging":
        plot_l2_error_distributions(l2_errors_dict, variable_names, "Kriging", str(save_dir),)
        plot_random_reconstruction(
            model="kriging",
            val_loader=test_loader,
            device=device,
            model_name="kriging",
            save_dir=str(save_dir),
            num_samples=7
        )
    elif mode == "cubic":
        plot_l2_error_distributions(l2_errors_dict, variable_names, "Cubic_Interpolation", str(save_dir),)
        plot_random_reconstruction(
            model="cubic_interpolation",
            val_loader=test_loader,
            device=device,
            model_name="cubic_interpolation",
            save_dir=str(save_dir),
            num_samples=7
        )
    
    return {
        "rrmse": np.mean(rrmse_total),
        "mae": np.mean(mae_total),
        "ssim": np.mean(ssim_total),
        "rrmse_per_var": rrmse_total,
        "mae_per_var": mae_total,
        "ssim_per_var": ssim_total,
        "l2_per_var": l2_errors,
    }

def evaluate(model_type, test_loader, checkpoint_path, variable_names=None, config_file=None):
    
    device = get_device()
    sample_input, _ = next(iter(test_loader))
    sample_input = sample_input.to(device)
    nb_channels = sample_input.shape[1]
    print(f'model_type: {model_type}')

    if model_type == "cubic_interpolation":
        evaluate_interp(test_loader, mode=3, nb_channels=nb_channels, variable_names=variable_names)
        return
    elif model_type == "kriging":
        evaluate_interp(test_loader, mode="kriging", nb_channels=nb_channels, variable_names=variable_names)
        return
    elif "gan" in model_type and 'injection_mode' in config_file and config_file['injection_mode'] == "first":
        print("ðŸŸ¢ Evaluating GAN with random noise injection (1st layer)")
        evaluate_ensemble_model(
            model_type=model_type,
            test_loader=test_loader,
            checkpoint_path=checkpoint_path,
            variable_names=variable_names,
            config_file=config_file
        )
        return
    elif "diffusion" in model_type:
        print("ðŸŸ¢ Evaluating Diffusion model")
        evaluate_ensemble_model(
            model_type=model_type,
            test_loader=test_loader,
            checkpoint_path=checkpoint_path,
            variable_names=variable_names,
            config_file=config_file
        )
        return
       

    model = create_model(model_type, nb_channels=nb_channels)
    if "gan" in model_type:
        model = model[0]
    # Insert channel check before loading state dict
    print(f"ðŸŸ¢ Generator input channels: {nb_channels}")
    print(f"ðŸŸ¢ Generator output channels: {model[-1].final.out_channels if hasattr(model[-1], 'final') else 'Unknown'}")
    model = model.to(device)
    checkpoint_path = os.path.join("models/saves", checkpoint_path)
    model.load_state_dict(torch.load(checkpoint_path, map_location=device))
    model.eval()
    print(f"âœ… Loaded model from {checkpoint_path}")
    print(f"âœ… Evaluating model on {len(test_loader.dataset)} samples")
    print(f"âœ… Model type: {model_type}")
    print(f"âœ… Device: {device}")

    rrmse_total, mae_total, ssim_total = [], [], []
    l2_errors = [[] for _ in range(nb_channels)]
    n_total = 0

    with torch.no_grad():
        pbar = tqdm(test_loader, desc="Testing")
        for inputs, targets in pbar:
            inputs, targets = inputs.to(device), targets.to(device)

            if model_type == "vae":
                recon_x, mu, logvar = model(inputs)
                preds = recon_x
            elif "vitae" in model_type:
                pred_dec, pred_enc = model(inputs)
                preds = pred_dec
            elif "gan" in model_type and 'gan_randomness' in config_file and config_file['gan_randomness'] == "True":
                injection_mode = config_file['gan_injection_mode']
                pass
            else:
                if "gan" in model_type: 
                    inputs = inputs[:, 1:, :, :]  # Skip the first channel if it's a mask
                preds = model(inputs)

            
                
            batch_size, nb_channels, H, W = targets.shape
            rrmse_batch, mae_batch, ssim_batch = [], [], []

            preds_np = preds.detach().cpu().numpy()
            targets_np = targets.detach().cpu().numpy()

            for v in range(nb_channels):
                preds_v = preds_np[:, v, :, :]
                targets_v = targets_np[:, v, :, :]

                rrmse_val = np.sqrt(np.mean((preds_v - targets_v) ** 2)) / (np.sqrt(np.mean(targets_v ** 2)) + 1e-8)
                mae_val = np.mean(np.abs(preds_v - targets_v))
                ssim_val = np.mean([
                    ssim(preds_v[i], targets_v[i], data_range=targets_v[i].max() - targets_v[i].min() + 1e-8)
                    for i in range(preds_v.shape[0])
                ])
                l2_vals = np.mean((preds_v - targets_v) ** 2, axis=(1, 2))
                l2_errors[v].extend(l2_vals.tolist())

                rrmse_batch.append(rrmse_val)
                mae_batch.append(mae_val)
                ssim_batch.append(ssim_val)

            rrmse_total.append(np.array(rrmse_batch) * batch_size)
            mae_total.append(np.array(mae_batch) * batch_size)
            ssim_total.append(np.array(ssim_batch) * batch_size)
            n_total += batch_size

            pbar.set_postfix({
                "RRMSE": np.mean(rrmse_batch),
                "MAE": np.mean(mae_batch),
                "SSIM": np.mean(ssim_batch)
            })

    rrmse_total = np.sum(rrmse_total, axis=0) / n_total
    mae_total = np.sum(mae_total, axis=0) / n_total
    ssim_total = np.sum(ssim_total, axis=0) / n_total

    if variable_names is None:
        variable_names = [f"Var{i}" for i in range(len(rrmse_total))]

    print("ðŸ“ˆ Per-variable Metrics:")
    for idx, var in enumerate(variable_names):
        print(f"âœ… {var}: RRMSE={rrmse_total[idx]:.4f}, MAE={mae_total[idx]:.4f}, SSIM={ssim_total[idx]:.4f}")

    print("\nðŸ“Š Overall Averages:")
    print(f"âœ… Avg RRMSE={np.mean(rrmse_total):.4f}, Avg MAE={np.mean(mae_total):.4f}, Avg SSIM={np.mean(ssim_total):.4f}")

    # Convert to dict
    l2_errors_dict = {var: l2_errors[i] for i, var in enumerate(variable_names)}

    # ðŸ“Š Plot L2 Error Distributions
    save_dir = Path("plots/evaluation")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    plot_l2_error_distributions(l2_errors_dict, variable_names, model_type, str(save_dir),)
    
    plot_random_reconstruction(
        model=model,
        val_loader=test_loader,
        device=device,
        model_name=model_type,
        save_dir=str(save_dir),
        num_samples
        =7
    )
    return {
        "rrmse": np.mean(rrmse_total),
        "mae": np.mean(mae_total),
        "ssim": np.mean(ssim_total),
        "rrmse_per_var": rrmse_total,
        "mae_per_var": mae_total,
        "ssim_per_var": ssim_total,
        "l2_per_var": l2_errors,
    }

def check_normalization(tensor, name="Tensor"):
    """
    Print min, max, mean, std to check normalization.
    """
    tensor_np = tensor.cpu().numpy()
    print(f"\n{name} stats:")
    print(f"  Min:  {tensor_np.min():.4f}")
    print(f"  Max:  {tensor_np.max():.4f}")
    print(f"  Mean: {tensor_np.mean():.4f}")
    print(f"  Std:  {tensor_np.std():.4f}")
    

def evaluate_ensemble_model(model_type, test_loader, checkpoint_path, variable_names=None, config_file=None, k=5):
    """
    Evaluate an ensemble model by averaging multiple predictions
    """
    
    device = get_device()
    sample_input, _ = next(iter(test_loader))
    sample_input = sample_input.to(device)
    nb_channels = sample_input.shape[1] -1

    
    
    if "gan" in model_type:
        model = create_model(model_type, nb_channels=nb_channels)
        model = model[0].to(device)
        print(f"ðŸŸ¢ Generator input channels: {nb_channels+1}")
        print(f"ðŸŸ¢ Generator output channels: {model.final.out_channels if hasattr(model, 'final') else 'Unknown'}")
    elif "diffusion" in model_type:
        model = create_model(model_type, nb_channels=nb_channels+1)
        T = 1000  # Number of diffusion steps, can be adjusted
        rn_rn_model = model.to(device)
        ddpm = DDPM(rn_rn_model, (1e-4, 0.02), T).to(device)
        model = ddpm
        
    checkpoint_path = os.path.join("models/saves", checkpoint_path)
    
    if "diffusion" in model_type:
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(torch.load(checkpoint_path, map_location=device))
        
    model.eval()
    
    print(f"âœ… Loaded model from {checkpoint_path}")
    print(f"âœ… Evaluating model on {len(test_loader.dataset)} samples")
    print(f"âœ… Model type: {model_type}")
    print(f"âœ… Device: {device}")
    
    # Limit to 200 samples for diffusion models to speed up evaluation
    max_samples = 200 if "diffusion" in model_type else len(test_loader.dataset)
    if "diffusion" in model_type:
        print(f"âš¡ Fast evaluation mode: limiting to {max_samples} samples for diffusion model")
    
    rrmse_total, mae_total, ssim_total = [], [], []
    l2_errors = [[] for _ in range(nb_channels)]
    n_total = 0

    with torch.no_grad():
        pbar = tqdm(test_loader, desc="Testing")
        for batch_idx, (inputs, targets) in enumerate(pbar):
            # Break early if we've processed enough samples for diffusion models
            if "diffusion" in model_type and n_total >= max_samples:
                print(f"âš¡ Reached {max_samples} samples limit for diffusion model evaluation")
                break
            print(f"Batch {batch_idx + 1}/{len(test_loader)}")
            
            inputs, targets = inputs.to(device), targets.to(device)
            all_preds = []

            for _ in range(k):
                # Prepare random input for each ensemble member
                if "gan" in model_type:
                    inputs_mod = inputs[:, 1:, :, :]  # Skip the first channel if it's a mask
                    z_random = torch.randn_like(inputs_mod[:, 0:1, :, :])  # shape: (B, 1, H, W)
                    inputs_random = torch.cat([inputs_mod, z_random], dim=1)
                    preds = model(inputs_random)
                    #Print the shape of the predictions
                    #print(f"Predictions shape: {preds.shape}")
                elif "diffusion" in model_type:
                    # Use the ddpm model to generate predictions. dont skip the first channel. to get the predictions we need sample()
                    cond = inputs  # Use full inputs as conditioning (including mask)
                    batch_size, _, H, W = targets.shape
                    
                    # Generate samples using the DDPM
                    preds = model.sample(
                        n_sample=batch_size,
                        size=(nb_channels, H, W),  # Size of the target tensor
                        device=device,
                        cond=cond  # Pass conditioning tensor
                    )
                else:
                    preds = model(inputs)
                all_preds.append(preds.cpu().numpy())

            all_preds = np.array(all_preds)  # shape: (k, B, C, H, W)
            all_preds_mean = np.mean(all_preds, axis=0)  # shape: (B, C, H, W)
            all_preds_var = np.var(all_preds, axis=0)

            batch_size, nb_channels, H, W = targets.shape
            rrmse_batch, mae_batch, ssim_batch = [], [], []

            preds_np = all_preds_mean
            targets_np = targets.detach().cpu().numpy()

            # If model_type is GAN and input channel was reduced, output nb_channels may be less by 1
            eval_channels = nb_channels
            for v in range(eval_channels):
                preds_v = preds_np[:, v, :, :]
                targets_v = targets_np[:, v, :, :]

                rrmse_val = np.sqrt(np.mean((preds_v - targets_v) ** 2)) / (np.sqrt(np.mean(targets_v ** 2)) + 1e-8)
                mae_val = np.mean(np.abs(preds_v - targets_v))
                ssim_val = np.mean([
                    ssim(preds_v[i], targets_v[i], data_range=targets_v[i].max() - targets_v[i].min() + 1e-8)
                    for i in range(preds_v.shape[0])
                ])
                l2_vals = np.mean((preds_v - targets_v) ** 2, axis=(1, 2))
                l2_errors[v].extend(l2_vals.tolist())

                rrmse_batch.append(rrmse_val)
                mae_batch.append(mae_val)
                ssim_batch.append(ssim_val)

            rrmse_total.append(np.array(rrmse_batch) * batch_size)
            mae_total.append(np.array(mae_batch) * batch_size)
            ssim_total.append(np.array(ssim_batch) * batch_size)
            n_total += batch_size

            pbar.set_postfix({
                "RRMSE": np.mean(rrmse_batch),
                "MAE": np.mean(mae_batch),
                "SSIM": np.mean(ssim_batch)
            })

    rrmse_total = np.sum(rrmse_total, axis=0) / n_total
    mae_total = np.sum(mae_total, axis=0) / n_total
    ssim_total = np.sum(ssim_total, axis=0) / n_total

    if variable_names is None:
        variable_names = [f"Var{i}" for i in range(len(rrmse_total))]

    print("ðŸ“ˆ Per-variable Metrics:")
    for idx, var in enumerate(variable_names):
        print(f"âœ… {var}: RRMSE={rrmse_total[idx]:.4f}, MAE={mae_total[idx]:.4f}, SSIM={ssim_total[idx]:.4f}")

    print("\nðŸ“Š Overall Averages:")
    print(f"âœ… Avg RRMSE={np.mean(rrmse_total):.4f}, Avg MAE={np.mean(mae_total):.4f}, Avg SSIM={np.mean(ssim_total):.4f}")

    # Convert to dict
    l2_errors_dict = {var: l2_errors[i] for i, var in enumerate(variable_names)}

    # ðŸ“Š Plot L2 Error Distributions
    save_dir = Path("plots/evaluation")
    save_dir.mkdir(parents=True, exist_ok=True)

    plot_l2_error_distributions(l2_errors_dict, variable_names, model_type, str(save_dir),)

    plot_random_reconstruction(
        model=model,
        val_loader=test_loader,
        device=device,
        model_name=model_type,
        save_dir=str(save_dir),
        num_samples=7
    )
    return {
        "rrmse": np.mean(rrmse_total),
        "mae": np.mean(mae_total),
        "ssim": np.mean(ssim_total),
        "rrmse_per_var": rrmse_total,
        "mae_per_var": mae_total,
        "ssim_per_var": ssim_total,
        "l2_per_var": l2_errors,
    }

                
                    