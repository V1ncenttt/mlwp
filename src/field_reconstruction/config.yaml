# config.yaml

project: mlwp-thesis-fieldreco
entity: your-wandb-username  # replace with your wandb user/org name


model:
  type: transformer           # or cnn, diffusion, etc.
  hidden_dim: 256
  num_layers: 6
  dropout: 0.1
  input_channels: 3          # e.g., T2M, U10, V10
  output_channels: 1         # e.g., T2M forecast

data:
  dataset: weatherbench2
  root_dir: /path/to/data
  resolution: 5.625deg
  variables: [t2m, u10, v10]


loss: cwgan_gp # Select from mse, mae, vae_elbo, smooth_l1, etc.

logging:
  log_every: 10
  save_every: 1
  use_wandb: true

split_ratio: 0.8
model: cwgan_gp

percent: 10
batch_size: 32
variables: 5vars_2d
output_dir: ../../data/weatherbench2_fieldreco/
optimizer: adam
learning_rate: 0.00005
weight_decay: 0.01
epochs: 25
tags: [baseline, transformer, lowres]
notes: Initial experiment using Transformer on WB2 5.625Â°
test:
  test_dataset: 
  model_path: generator_model_25_5237835.567076.pth
  model_type: cwgan_gp

injection_mode: first


wandb:
  project: mlwp-thesis-fieldreco
  entity: your-wandb-username  # replace with your wandb user/org name


